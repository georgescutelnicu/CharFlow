{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries and file**"
      ],
      "metadata": {
        "id": "RqvrzUDfcpff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "-AguGbiUfJeA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import file and read first 10 words **the file should contain one word per row**\n",
        "names = open('names.txt', 'r').read().splitlines()\n",
        "names[:10]"
      ],
      "metadata": {
        "id": "D6T4h5eZfMWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7450507-391e-419b-9120-b6d5a6ea5e3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BELLA',\n",
              " 'LUCY',\n",
              " 'SADIE',\n",
              " 'MAX',\n",
              " 'BUDDY',\n",
              " 'BAILEY',\n",
              " 'CHARLIE',\n",
              " 'DAISY',\n",
              " 'JACK',\n",
              " 'GINGER']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vocabulary**"
      ],
      "metadata": {
        "id": "nNz2L6XGPuK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vocabulary and the start/end token \".\"\n",
        "char = set(''.join(names))\n",
        "\n",
        "char_to_idx = {char: idx+1 for idx, char in enumerate(sorted(char))}\n",
        "char_to_idx['.'] = 0\n",
        "\n",
        "idx_to_char = {v: k for k, v in char_to_idx.items()}"
      ],
      "metadata": {
        "id": "-V4kaS_B1CPl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary size\n",
        "VOCAB_SIZE = len(idx_to_char)"
      ],
      "metadata": {
        "id": "r_0rxKoj3MhZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**"
      ],
      "metadata": {
        "id": "Tin-YtJP5qu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many characters should we get in order to predict the next one\n",
        "CONTEXT_SIZE = 3"
      ],
      "metadata": {
        "id": "giCo9pX-1tfG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Where to split data\n",
        "n = int(0.9*len(names))"
      ],
      "metadata": {
        "id": "cXKMkZFEcN3l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset function\n",
        "def create_dataset(names=names):\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for name in names:\n",
        "    x_ = CONTEXT_SIZE * [0]\n",
        "    for ch in name + '.':\n",
        "      X.append(x_)\n",
        "      y.append(char_to_idx[ch])\n",
        "      x_ = x_[1:] + [char_to_idx[ch]]\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  y = torch.tensor(y)\n",
        "  \n",
        "  return X, y"
      ],
      "metadata": {
        "id": "77CPAVxA40oe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test datasets\n",
        "X, y = create_dataset(names[:n])\n",
        "X_test, y_test = create_dataset(names[n:])"
      ],
      "metadata": {
        "id": "A9er6paf5dTx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape and dtype of the X and y\n",
        "X.shape, X.dtype, y.shape, y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NJEz_KOnvEq",
        "outputId": "4ecf6d55-caf3-45f5-c621-1b5e5cafacf5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([84796, 3]), torch.int64, torch.Size([84796]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Check shape and dtype of the X_test and y_test\n",
        "X_test.shape, X_test.dtype, y_test.shape, y_test.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI_Eu9305mUX",
        "outputId": "11f16799-940d-47bb-a0b2-6bc0cdc4ab6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([9479, 3]), torch.int64, torch.Size([9479]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "CsT2YUi-nmQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture\n",
        "class LinearLayer:\n",
        "\n",
        "  def __init__(self, in_features, hidden_units):\n",
        "    self.W = torch.randn((in_features, hidden_units)) * 0.01\n",
        "    self.b = torch.randn(hidden_units) * 0\n",
        "\n",
        "  def __call__(self, X):\n",
        "    self.out = X @ self.W + self.b\n",
        "    return self.out\n",
        "\n",
        "  def params(self):\n",
        "    return [self.W] + [self.b]  # '+', ','\n",
        "\n",
        "\n",
        "class BatchNormalization:\n",
        "\n",
        "  def __init__(self, dim, training=True):\n",
        "    self.training = training\n",
        "\n",
        "    # Parameters\n",
        "    self.batch_gain = torch.ones(dim)\n",
        "    self.batch_bias = torch.zeros(dim)\n",
        "\n",
        "    # Buffers\n",
        "    self.all_batch_mean = torch.zeros(dim)\n",
        "    self.all_batch_std = torch.ones(dim)\n",
        "\n",
        "  def __call__(self, X):\n",
        "    if self.training:\n",
        "      batch_mean = X.mean(0, keepdim=True)\n",
        "      batch_std = X.std(0, keepdim=True)\n",
        "      with torch.no_grad():\n",
        "        self.all_batch_mean = 0.99 * self.all_batch_mean + 0.01 * batch_mean\n",
        "        self.all_batch_std = 0.99 * self.all_batch_std + 0.01 * batch_std\n",
        "    else:\n",
        "      batch_mean = self.all_batch_mean\n",
        "      batch_std = self.all_batch_std\n",
        "\n",
        "    self.out = self.batch_gain * (X - batch_mean) / batch_std + self.batch_bias\n",
        "    return self.out\n",
        "\n",
        "  def params(self):\n",
        "    return [self.batch_gain, self.batch_bias]\n",
        "\n",
        "\n",
        "class TanH:\n",
        "\n",
        "  def __call__(self, X):\n",
        "    self.out = torch.tanh(X)\n",
        "    return self.out\n",
        "  \n",
        "  def params(self):\n",
        "    return []\n",
        "\n",
        "\n",
        "class Embeddings:\n",
        "\n",
        "  def __init__(self, vocab_size, emb_size):\n",
        "    self.emb = torch.randn((vocab_size, emb_size))\n",
        "\n",
        "  def __call__(self, X):\n",
        "    self.out = self.emb[X]\n",
        "    self.out = self.out.view(self.out.shape[0], -1)\n",
        "    return self.out\n",
        "\n",
        "  def params(self):\n",
        "    return [self.emb]\n",
        "\n",
        "\n",
        "class Sequential:\n",
        "  \n",
        "  def __init__(self, layers):\n",
        "    self.layers = layers\n",
        "  \n",
        "  def __call__(self, X):\n",
        "    for layer in self.layers:\n",
        "      X = layer(X)\n",
        "    self.out = X\n",
        "    return self.out\n",
        "  \n",
        "  def params(self):\n",
        "    return [p for layer in self.layers for p in layer.params()]"
      ],
      "metadata": {
        "id": "QK3Bq-sTUdqs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters**"
      ],
      "metadata": {
        "id": "h0Xl64aiZ7_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "EMB_SIZE = 20\n",
        "HIDDEN_UNITS = 200\n",
        "BATCH_SIZE = 32\n",
        "STEPS = 300000"
      ],
      "metadata": {
        "id": "1ByDgq_NZ7Zc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create model & set the parameters to require grad**"
      ],
      "metadata": {
        "id": "qEl190MjaEfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model\n",
        "model = Sequential([\n",
        "  Embeddings(VOCAB_SIZE, EMB_SIZE),\n",
        "  LinearLayer(EMB_SIZE * CONTEXT_SIZE, HIDDEN_UNITS), BatchNormalization(HIDDEN_UNITS), TanH(),\n",
        "  LinearLayer(HIDDEN_UNITS, HIDDEN_UNITS), BatchNormalization(HIDDEN_UNITS), TanH(),\n",
        "  LinearLayer(HIDDEN_UNITS, VOCAB_SIZE),\n",
        "])"
      ],
      "metadata": {
        "id": "DDtCH0UTi-5O"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the parameters to require grad\n",
        "parameters = model.params()\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "e8tOnXJpkNp6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Forward pass**"
      ],
      "metadata": {
        "id": "PJuhQwJAaQ-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list to store all the loss values\n",
        "loss_list = []\n",
        "\n",
        "# Forward pass\n",
        "for i in range(STEPS):\n",
        "\n",
        "  idx = torch.randint(0, X.shape[0], (BATCH_SIZE, ))\n",
        "  X_batch, y_batch = X[idx], y[idx]\n",
        "  \n",
        "  logits = model(X_batch)\n",
        "  loss = F.cross_entropy(logits, y_batch) # loss function\n",
        "\n",
        "  # Backpropagation\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "  \n",
        "  # Lr decay\n",
        "  if i < 200000:\n",
        "    lr = -0.01\n",
        "  elif i < 100000:\n",
        "    lr = -0.1\n",
        "  else:\n",
        "    lr = -0.001\n",
        "\n",
        "  # Update the parameters\n",
        "  for p in parameters:\n",
        "    p.data += lr * p.grad\n",
        "\n",
        "  # Track loss every 10000 steps and append all the loss values to a list\n",
        "  if i % 10000 == 0:\n",
        "    print(f'{loss.item():.4f}')\n",
        "  loss_list.append(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBUijeC9mmu6",
        "outputId": "79145db6-0758-46d3-9a09-0c45e49e3eae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3185\n",
            "2.4616\n",
            "2.0431\n",
            "2.0191\n",
            "1.8910\n",
            "1.9696\n",
            "2.0139\n",
            "2.1667\n",
            "1.9469\n",
            "1.9474\n",
            "1.8738\n",
            "1.8404\n",
            "1.5918\n",
            "2.0459\n",
            "1.7811\n",
            "2.0652\n",
            "2.3293\n",
            "1.8020\n",
            "1.4326\n",
            "1.4245\n",
            "1.5819\n",
            "1.6157\n",
            "1.8667\n",
            "1.6163\n",
            "1.7843\n",
            "1.5741\n",
            "1.7781\n",
            "1.8490\n",
            "1.7232\n",
            "1.5303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss curve**"
      ],
      "metadata": {
        "id": "3xXx3twcacBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curve\n",
        "plt.plot(torch.tensor(loss_list).view(-1, 10000).mean(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "onFYZjg7pEl3",
        "outputId": "247b545c-f79c-4903-b066-3249ab8be551"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb2de8945e0>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check test loss**"
      ],
      "metadata": {
        "id": "3-MaQPB5ahin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the BN training attribute to False\n",
        "for layer in model.layers:\n",
        "  layer.training = False"
      ],
      "metadata": {
        "id": "HqoPrN9Qan1C"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the loss\n",
        "def check_loss(data='train'):\n",
        "  with torch.no_grad():\n",
        "    X_,y_ = {\n",
        "      'train': (X, y),\n",
        "      'test': (X_test, y_test)\n",
        "    }[data]\n",
        "    logits = model(X_)\n",
        "    loss = F.cross_entropy(logits, y_)\n",
        "  print(data, loss.item())"
      ],
      "metadata": {
        "id": "MNmTNeIZwB7j"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train loss\n",
        "check_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iolbrr4DwC9_",
        "outputId": "0e5ed07a-360b-4e35-a42a-ed2e2f98767f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 1.7322505712509155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test loss\n",
        "check_loss('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u12KPQo9wEg8",
        "outputId": "96da4715-308b-4196-8e82-3077782296a2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test 2.0458731651306152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 15 predictions\n",
        "for _ in range(15):\n",
        "\n",
        "  out_list = []\n",
        "  context = CONTEXT_SIZE * [0]\n",
        "  while True:\n",
        "\n",
        "    logits = model(torch.tensor([context]))\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    idx = torch.multinomial(probs, num_samples=1).item() # Draw samples from a multinomial distribution.\n",
        "\n",
        "    context = context[1:] + [idx]\n",
        "    out_list.append(idx)\n",
        "  \n",
        "    if idx == 0:\n",
        "      break\n",
        "    \n",
        "  print(''.join(idx_to_char[idx] for idx in out_list[:-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nstf4yy_wG_a",
        "outputId": "8c4fd22b-3a2d-4e6a-c7f4-3b5a7d5218b5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PANDALF\n",
            "PIPPER\n",
            "BRUSHILDA\n",
            "DOZER\n",
            "TAMAK\n",
            "HAYLA\n",
            "WRENA\n",
            "JULIE\n",
            "BINNIE\n",
            "BREEZLE\n",
            "BLAZEE\n",
            "PAX\n",
            "BANSHINGTON\n",
            "AUGE\n",
            "NETO\n"
          ]
        }
      ]
    }
  ]
}